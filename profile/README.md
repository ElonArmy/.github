## Hi there 👋 This is SCANNER TEAM's GitHub 😎

## Brif.
- 이미지에서 문서를 detection(객체 인식) 하고 왜곡된 문서를 dewarping(평활화)한다 => 최종적으로 깔끔한 문서 제공
- 노션에서 회의록, 참고자료, 일정 공유(https://www.notion.so/Scanner-with-DL-Project-34c124568fc04850b49af604875daf35)
- 어떤 서비스를 어떻게 제공 할 것인가 => 수립해야 프로젝트 시작 가능
- 서비스 정확히 어떤것을 어떻게 구현할지 정하기(클라이언트(이미지업로드 또는 내장카메라 사용해서 이미지 촬영 후 서버로 전달) => 서버(전처리 후 데이터를 모델API에 전달)) <=> 모델serving api( 받은 데이터를 모델에 넣고 예측해서 예측 값(이미지)을 서버에 다시 전달)  => 서버(예측 이미지를 모두받으면 pdf파일로 변환) => 클라이언트( pdf파일을 전달받고 유저에게 제공)

## Task
### 2/5
  - PageEdge 모델 분석 및 구현, 사전학습 모델 파인튜닝할 데이터 생성 정의
  - docUnet 데이터생성기 상세히 조사해보기

### 1/27
  - RCF 기능추가는 더이상 하지않는걸로
  - 찬란 ⇒ 논문 발전과정 조사하면서 핵심 구조등 기초 기술(코드) 수집, rectinet 사전학습 모델을 사용해서 테스트 해보기, 성능과 결과물의 상태 => rectinet, PageEdge모델 테스트 후 PageEdge가 적합하다고 판단
  - 지섭님 => docunet 모델 , 데이터생성해서 학습 시키고 책페이지에 대한 결과물 테스트 해보기 docunet 깃허브에 상세히 설명되어있음, 성능과 결과물의 상태 => docUnet 데이터 생성 툴 활용 가능성 확인
    
### 1/15 기준 현재 목표
  - 만들어진 장고 웹서버에 문서 꼭짓점 네점을 찾지 못할 경우 사용자 수정 좌표 받아와서 이미지 처리하는거 합치기, 프론트 <=> 모델 간 좌표교환  => 완료
  - dewarp 모델의 핵심구조에 따라 기본적인 간단한 모델 만들어서 합쳐보기 (공간변형 네트워크, 박막-스플라인, 텍스쳐 매핑, 이진화 또는 푸리에변환) => 실패

    
### 1/8 기준 현재 목표
  - 웹서비스 구현 => 장고서버를 만들어서 딥러닝 모델을 같이 올려서 구현해보기  => 완료
  - 이미지 문서 꼭짓점 네점을 찾지 못할 경우 => 사용자가 꼭짓점을 찍어서 보내주는 기능 구현  => 완료
  - 찬란 => facd3d 툴 조사                  => 완료, 사용하기 힘듦(오래된 버전 의존성문제 해결못했음, 데이터셋 링크 소실)
  - 지섭님 => 모델 서빙API 구현하기    => api 정의 완료

### 1/2 기준 현재 목표
  - 프로토타입: 기초적인 openCV 스캔기능을 가지고 모델API서버(Fast api) 및 기초적인 프론트(RN)와 백엔드 서버(JavaSpring)구성해서 프로토타입을 만들어 보는 것
  - UI를 그려서 프론트 가이드라인 잡아주기  => 완료
  - 난이도가 높은 딥러닝 모델구현팀은 가이드 논문을 토대로 모델을 구현, 모델학습에 필요한 가상 학습 데이터를 정의하여 시뮬레이션팀에게 요청 => 실패, 데이터 정의 및 생성하는데 툴을 활용하기 어려움
    
### 소스코드나 조사자료에 최대한 주석을 많이 달아 주세요 

## 방법

### 함수 설명
- 원본이미지가 x이고 unwarping 결과물이 $x_t$일 때 $$x_t = \phi(\phi(x,d_E),d_T)$$
- 2D 와핑함수 $\phi(a1,a2)$가 있을때 a2의 변형 필드(=이하 변형그리드)를 기반으로 a1을 변형한다. 
- $d_E$는 Enet에서 나온 경계기반변형그리드, $d_T$는 Tnet의 텍스쳐기반변형그리드이다
- 변형 필드란 쉽게 말해 원본이미지에서 어느 위치의 픽셀값을 가져와야하는지 알려주는 것이다. 역방향 매핑이란 이런 샘플링 위치를 결정하는 하나의 방법이다

### Enet 아키텍처 설명
- FCN구조, factor of 2(가로축, 세로축)의 특징맵을 샘플링하는 residual block을 사용하는 인코더와 디코더로 이루어짐
- 256 X 256 X 5 인 Enet 입력 텐서는 이미지의 RGB와 coordinates(좌표)가 합쳐진것이다
- d* 는 인공이미지에서 ground-truth 이미지로의 변형필드인데 (NXNX2)차원이며 크기는 $d_E$와 동일하다. Enet에서는 $d_E$와 d*의 경계요소를 맞추도록 학습시킨다.
- 손실함수 (인공적으로 생성된 데이터를 학습할때 완전-지도학습) $$L_{SE} = |B(d_E)-B(d^*)|_1$$
- B()는 변형필드에서 경계를 추출하는 함수이다. 즉 변형필드의 경계요소만으로도 문서에 포함되는 모든 픽셀 샘플위치를 추정할수있으며, 선형보간으로 복원하는게 가능하다는것이다
- 인공데이터 학습 후 실제 문서의 이미지를 Enet에 학습시킬때는 약한-지도학습에 사용한다
- 손실함수(실제이미지를 학습할때) $$L_M=|\phi(y,d_E)-m|_1$$
- d_E가 Enet의 출력된 변형필드이고, m은 사각형 마스크이미지이다.
- 그러나 위의 손실함수는 단순히 경계를 늘리는 것에대한 손실함수이고 현실의 문서가 복원되는 정확한 정보에 대해서는 부정확하다. 따라서 a cycle-consistent segmentation mask loss라는 손실함수를 사용해야한다.
$ L_M=|\phi(y,d_E)-m|_1 + |\phi(m,d^{-1}_{E}-y)|_1 $
- $d^{-1}_{E}$는 $d_E$의 뒤집어진 변형필드이다. 아무튼 이런 역방향 변형필드를 만들어서 다항하모닉 스플라인 어쩌구 함수를 만들어 사용할수있다고 한다(어려워서 중략)
- 즉, 사각형 마스크에 변형필드를 적용해 이미지의 찌그러진 문서를 만들어내서 정방향 변형과 손실함수를 비교하면서 문서내부의 정보를 잃지 않는다는 것인듯.


### 모델학습한 방법
- 현실 문서의 annotation인 DIW 5000개와 인조적인 Doc3D데이터 8만8천개를 학습시킴
- 인조의 데이터만 학습 시키는 것은 어느 수준을 넘어가면 정확도가 향상되지 않는다. 따라서 현실의 데이터가 효과적으로 도메인갭을 보완해준다
- Enet은 doc3d(인조)데이터셋으로 학습된 모델에 diw(현실) 데이터셋이 파인튜닝된것이다.
- 그 이후, Enet의 가중치는 고정되고, 해당 출력으로 Tnet을 학습하는 과정을 거친다
- 미작성

### 한계
- 문서의 본래 3D 형태를 알지못하는 방법론이다
